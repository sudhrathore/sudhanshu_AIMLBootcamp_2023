{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16QMnrzY9Ch5y6dFwQveT_qrzqhDEXM1o",
      "authorship_tag": "ABX9TyP1DPjXO8bAVz6sp1uIh+Ek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudhrathore/sudhanshu_AIMLBootcamp_Genzeon_2023/blob/main/NLP_Day1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jv78bu5CwITP"
      },
      "outputs": [],
      "source": [
        "text1=\"Natural Language Procession is a subfield of AI\"\n",
        "tag1=\"NLP\"\n",
        "text2=\"computer Vision is a subfield of AI \"\n",
        "tag2=\"CV\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "texts = [text1, text2]\n",
        "tags = [tag1, tag2]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "vectorized_texts = vectorizer.fit_transform(texts)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "frequency_table=vectorized_texts.toarray()\n",
        "print(\"Feature names:\")\n",
        "print(feature_names)\n",
        "\n",
        "print(\"Vectorized texts:\")\n",
        "print(vectorized_texts.toarray())\n",
        "\n",
        "df = pd.DataFrame(frequency_table, columns=feature_names)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Add the text and tag columns\n",
        "\n",
        "df['Text'] = [text1, text2]\n",
        "\n",
        "df['Tag'] = [tag1, tag2]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Print the DataFrame\n",
        "\n",
        "print(df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GhjQZF2gU8z",
        "outputId": "6d972eaa-69e9-400d-b98a-40b0cb7a445d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature names:\n",
            "['ai' 'computer' 'is' 'language' 'natural' 'of' 'procession' 'subfield'\n",
            " 'vision']\n",
            "Vectorized texts:\n",
            "[[1 0 1 1 1 1 1 1 0]\n",
            " [1 1 1 0 0 1 0 1 1]]\n",
            "   ai  computer  is  language  natural  of  procession  subfield  vision  \\\n",
            "0   1         0   1         1        1   1           1         1       0   \n",
            "1   1         1   1         0        0   1           0         1       1   \n",
            "\n",
            "                                              Text  Tag  \n",
            "0  Natural Language Procession is a subfield of AI  NLP  \n",
            "1             computer Vision is a subfield of AI    CV  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(['punkt','wordnet']) #lexical db fro english lang #punkt-tokenizer model for various lang\n",
        "nltk.download('omw-1.4') #Open multiligual Wordnet - 1.4 -Wordnet for multiple languages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLtzRJTdABbM",
        "outputId": "07a52815-2199-4a06-9fea-65581f482278"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemm = WordNetLemmatizer()\n",
        "\n",
        "print(lemm.lemmatize(\"mouse\"))\n",
        "print(lemm.lemmatize(\"feet\"))\n",
        "print(lemm.lemmatize(\"misery\"))\n",
        "print(lemm.lemmatize(\"caring\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZBgwhV9ApTZ",
        "outputId": "b235a87a-9e4c-4fe2-bc03-61a46958dab3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mouse\n",
            "foot\n",
            "misery\n",
            "caring\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"My grandma is very caring. The striped bats are hanging on their feet\"\n",
        "\n",
        "#Tokenisation\n",
        "\n",
        "li_words=nltk.word_tokenize(sentence)\n",
        "print(li_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh7DrU9mBRCW",
        "outputId": "f1dd1a0b-e916-40b8-ef6a-62b40876319d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My', 'grandma', 'is', 'very', 'caring', '.', 'The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = [lemm.lemmatize(w) for w in li_words]\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kbFxy9LBw05",
        "outputId": "ce21712e-72b5-49f9-d506-7c8c740c8496"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My',\n",
              " 'grandma',\n",
              " 'is',\n",
              " 'very',\n",
              " 'caring',\n",
              " '.',\n",
              " 'The',\n",
              " 'striped',\n",
              " 'bat',\n",
              " 'are',\n",
              " 'hanging',\n",
              " 'on',\n",
              " 'their',\n",
              " 'foot']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Provide POS (Parts of speech) tag as second argument to lemmitize()**\n"
      ],
      "metadata": {
        "id": "kHT0fQ6rDD1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemm.lemmatize(\"hanging\",\"v\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh0JO0yvCPjE",
        "outputId": "b23e1831-ae6b-4b6f-f11f-d282af3494a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hang\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemm.lemmatize(\"stripes\",\"v\"))\n",
        "print(lemm.lemmatize(\"stripes\",\"n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRS1Z6FfDYEJ",
        "outputId": "6cb444b1-7cce-4d6c-ddd8-9a1071ddb1ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "strip\n",
            "stripe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WordNet lemmatizer with POS tag**"
      ],
      "metadata": {
        "id": "17LA392MD9DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0EoqjJHEQIz",
        "outputId": "30388d6a-8786-4a4b-a5da-fd3761416b1c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos_tag(word):\n",
        "  tag=nltk.pos_tag([word])\n",
        "  return tag\n",
        "\n",
        "get_wordnet_pos_tag(\"couragous\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlLYC-JJD08L",
        "outputId": "450076c8-1124-43d1-b5c1-4b57b4035202"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('couragous', 'JJ')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader import wordnet\n",
        "def get_wordnet_pos_tag(word):\n",
        "  tag=nltk.pos_tag([word])[0][1][0]\n",
        "  tag_dict={\n",
        "      \"J\":wordnet.ADJ,\n",
        "      \"R\":wordnet.ADV,\n",
        "      \"N\":wordnet.NOUN,\n",
        "      \"V\":wordnet.VERB\n",
        "  }\n",
        "  print(tag)\n",
        "  return tag_dict.get(tag,wordnet.NOUN) #default tag -POS tag - when the word not classifies as any predefined POS\n",
        "\n",
        "\n",
        "get_wordnet_pos_tag(\"caring\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "AWEl0Vg1FXF1",
        "outputId": "796fa8e0-b36c-47c7-e92f-ac393757fcd0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'v'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemm=WordNetLemmatizer()\n",
        "word=\"Honest\"\n",
        "print(lemm.lemmatize(word,get_wordnet_pos_tag(word)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26Fw6xifHLHH",
        "outputId": "89be36db-837d-4fb1-d25b-6d9eb897772f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "J\n",
            "Honest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"My grandma is very caring. The striped bats are hanging on their feet\"\n",
        "\n",
        "#Tokenisation\n",
        "\n",
        "li_words=nltk.word_tokenize(sentence)\n",
        "print(li_words)\n",
        "\n",
        "output = [lemm.lemmatize(w,get_wordnet_pos_tag(w)) for w in li_words]\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utDJgO4gH1B9",
        "outputId": "0bd505cf-2bb5-4da9-d0cf-91095799ecbd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My', 'grandma', 'is', 'very', 'caring', '.', 'The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet']\n",
            "P\n",
            "N\n",
            "V\n",
            "R\n",
            "V\n",
            ".\n",
            "D\n",
            "V\n",
            "N\n",
            "V\n",
            "V\n",
            "I\n",
            "P\n",
            "N\n",
            "['My', 'grandma', 'be', 'very', 'care', '.', 'The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "sp_nlp=spacy.load('en_core_web_sm') #updated model name\n",
        "sentence=\"My Grandma is very caring. The striped bats are hanging on thier feet\"\n",
        "\n",
        "#prse the sentence using the lang midel -'en_core_web_sm'\n",
        "doc=sp_nlp(sentence)\n",
        "print(doc)\n",
        "\n",
        "#extract lemma for each token in sentence\n",
        "output=[token.lemma_ for token in doc]\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-aYGSOHIySj",
        "outputId": "f2639ff4-a972-40e1-d088-4281ceaf56b3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My Grandma is very caring. The striped bats are hanging on thier feet\n",
            "['my', 'Grandma', 'be', 'very', 'caring', '.', 'the', 'stripe', 'bat', 'be', 'hang', 'on', 'thi', 'foot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Id26jzCKhbO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}